{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f046784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb53ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSNN(nn.Module):\n",
    "    def __init__(self, T: int, channels: int, use_cupy=False):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "        layer.Conv2d(1, channels, kernel_size=3, padding=1, bias=False), # 28*28\n",
    "        layer.BatchNorm2d(channels),\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        layer.MaxPool2d(2, 2),  # 14 * 14\n",
    "\n",
    "        layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),\n",
    "        layer.BatchNorm2d(channels),\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        layer.MaxPool2d(2, 2),  # 7 * 7\n",
    "\n",
    "        layer.Flatten(), # 7*7 -> 49*1\n",
    "        layer.Linear(channels * 7 * 7, channels * 4 * 4, bias=False), # 7*7 -> 4*4\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "\n",
    "        layer.Linear(channels * 4 * 4, 10, bias=False),\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "\n",
    "        if use_cupy:\n",
    "            functional.set_backend(self, backend='cupy')\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)\n",
    "        x_seq = self.conv_fc(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1a33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ed831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FMIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:07<00:00, 3.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FMIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FMIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FMIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 105kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FMIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FMIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FMIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 2.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FMIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FMIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FMIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FMIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FMIST/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"LIF FMNIST Training\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=\"data/FMIST\")\n",
    "    parser.add_argument(\"--device\", type=str, default=('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    parser.add_argument(\"-T\", default=1, type=int, help=\"simulating time-steps\")\n",
    "    parser.add_argument(\"-b\", default=64, type=int, help=\"batch size\")\n",
    "    parser.add_argument(\n",
    "        \"-epochs\",\n",
    "        default=3,\n",
    "        type=int,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of total epochs to run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-j\",\n",
    "        default=4,\n",
    "        type=int,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of data loading workers (default: 4)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-out-dir\",\n",
    "        type=str,\n",
    "        default=\"./logs\",\n",
    "        help=\"root dir for saving logs and checkpoint\",\n",
    "    )\n",
    "    parser.add_argument(\"-resume\", type=str, help=\"resume from the checkpoint path\")\n",
    "    parser.add_argument(\n",
    "        \"-amp\", action=\"store_true\", help=\"automatic mixed precision training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-opt\",\n",
    "        type=str,\n",
    "        choices=[\"sgd\", \"adam\"],\n",
    "        default=\"adam\",\n",
    "        help=\"use which optimizer. SGD or Adam\",\n",
    "    )\n",
    "    parser.add_argument(\"-momentum\", default=0.9, type=float, help=\"momentum for SGD\")\n",
    "    parser.add_argument(\"-lr\", default=1e-3, type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\n",
    "        \"-tau\", default=2.0, type=float, help=\"parameter tau of LIF neuron\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "    net = CSNN(T=args.T, channels=32, use_cupy=False)\n",
    "    net.to(args.device)\n",
    "\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(\n",
    "        root=args.data_dir,\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        download=True)\n",
    "\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(\n",
    "        root=args.data_dir,    \n",
    "        train=False,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        download=True)\n",
    "\n",
    "    train_data_loader = data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=args.b,\n",
    "        shuffle=True, # 매 epoch 시작마다 데이터 섞기\n",
    "        drop_last=True, # 남는 자투리 데이터 버린다\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True, # 메모리 고정\n",
    "    )\n",
    "    test_data_loader = data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=args.b,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
