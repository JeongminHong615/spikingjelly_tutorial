{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a88a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40778/2264697284.py:12: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, 'object'):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NumPy 호환성 패치 (NumPy 1.20+ 대응)\n",
    "if not hasattr(np, 'int'):\n",
    "    np.int = int\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float\n",
    "if not hasattr(np, 'bool'):\n",
    "    np.bool = bool\n",
    "if not hasattr(np, 'complex'):\n",
    "    np.complex = complex\n",
    "if not hasattr(np, 'object'):\n",
    "    np.object = object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4580fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import spikingjelly\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer, encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca828b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=False)\n",
       "  (2): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential( # stack layer\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 10, bias=False), # 학습 X, (input 수, output 수) => (input, 10)\n",
    "    nn.Softmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d14ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2.0\n",
    "net = nn.Sequential(\n",
    "    layer.Flatten(),\n",
    "    layer.Linear(28 * 28, 10, bias=False),\n",
    "    neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5817f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# Use PoissonEncoder\n",
    "encoder = encoding.PoissonEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d207d",
   "metadata": {},
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a098abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.cuda import amp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b996bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, tau):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(28 * 28, 10, bias=False),\n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04aee978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T=100, device='cuda:0', b=64, epochs=100, j=4, data_dir=None, out_dir='./logs', resume=None, amp=False, opt='adam', momentum=0.9, lr=0.001, tau=2.0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"LIF MNIST Training\")\n",
    "parser.add_argument(\"-T\", default=100, type=int, help=\"simulating time-steps\")\n",
    "parser.add_argument(\"-device\", default=\"cuda:0\", help=\"device\")\n",
    "parser.add_argument(\"-b\", default=64, type=int, help=\"batch size\")\n",
    "parser.add_argument(\n",
    "        \"-epochs\",\n",
    "        default=100,\n",
    "        type=int,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of total epochs to run\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"-j\",\n",
    "        default=4,\n",
    "        type=int,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of data loading workers (default: 4)\",\n",
    "    )\n",
    "parser.add_argument(\"-data-dir\", type=str, help=\"root dir of MNIST dataset\")\n",
    "parser.add_argument(\n",
    "        \"-out-dir\",\n",
    "        type=str,\n",
    "        default=\"./logs\",\n",
    "        help=\"root dir for saving logs and checkpoint\",\n",
    "    )\n",
    "parser.add_argument(\"-resume\", type=str, help=\"resume from the checkpoint path\")\n",
    "parser.add_argument(\n",
    "        \"-amp\", action=\"store_true\", help=\"automatic mixed precision training\"\n",
    "    )\n",
    "parser.add_argument(\n",
    "        \"-opt\",\n",
    "        type=str,\n",
    "        choices=[\"sgd\", \"adam\"],\n",
    "        default=\"adam\",\n",
    "        help=\"use which optimizer. SGD or Adam\",\n",
    "    )\n",
    "parser.add_argument(\"-momentum\", default=0.9, type=float, help=\"momentum for SGD\")\n",
    "parser.add_argument(\"-lr\", default=1e-3, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\n",
    "        \"-tau\", default=2.0, type=float, help=\"parameter tau of LIF neuron\"\n",
    "    )\n",
    "\n",
    "args = parser.parse_args([]) # 오류 : Jupyter Notebook에서 argparse 사용 시, 빈 리스트를 전달하여 기본값을 사용하도록 설정\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211260f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNN(\n",
      "  (layer): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1, step_mode=s)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=False)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SNN(tau=args.tau)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f2fe08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNN(\n",
       "  (layer): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1, step_mode=s)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=False)\n",
       "    (2): LIFNode(\n",
       "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch, tau=2.0\n",
       "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465461e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "        root=args.data_dir if args.data_dir else './data',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        download=True,\n",
    "    )\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "        root=args.data_dir if args.data_dir else './data',\n",
    "        train=False,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "train_data_loader = data.DataLoader(\n",
    "        dataset=train_dataset, # 어느 데이터 불러올지\n",
    "        batch_size=args.b,\n",
    "        shuffle=True, # epoch마다 데이터 섞기\n",
    "        drop_last=True, # 나누어떨어지지 않는 마지막 batch 버리기\n",
    "        num_workers=args.j,# subprocess 수\n",
    "        pin_memory=True, # cpu 공간 고정. gpu로 옮길 때 빠르게 옮길 수 있도록 도와줌\n",
    "    )\n",
    "test_data_loader = data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=args.b,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74e4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e165dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.amp: # gpu 속도 향상\n",
    "    scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09a52b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "max_test_acc = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc54301",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = None\n",
    "if args.opt == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            net.parameters(), lr=args.lr, momentum=args.momentum\n",
    "        )\n",
    "elif args.opt == \"adam\":\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "else:\n",
    "        raise NotImplementedError(args.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume: # 학습 재개. 체크포인트 데이터 불러오기\n",
    "        checkpoint = torch.load(args.resume, map_location=\"cpu\")\n",
    "        net.load_state_dict(checkpoint[\"net\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        max_test_acc = checkpoint[\"max_test_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(args.out_dir, f\"T{args.T}_b{args.b}_{args.opt}_lr{args.lr}\")\n",
    "''' 파일 경로 합치기. \n",
    "붙일 경로가 /로 시작하면 앞에 경로 버리기\n",
    "/가 없거나 앞의 경로에 붙어있다면 그냥 경로 잇기'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.amp:\n",
    "    out_dir += \"_amp\" # 경로 이름 끝에 _amp 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee8ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mkdir ./logs/T100_b64_adam_lr0.001.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(out_dir): # out_dir이 존재하지 않으면 만들기\n",
    "    os.makedirs(out_dir)\n",
    "    print(f\"Mkdir {out_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbae19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, \"args.txt\"), \"w\", encoding=\"utf-8\") as args_txt:\n",
    "    args_txt.write(str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de066d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(out_dir, purge_step=start_epoch) # 로그 저장하는 파일 생성\n",
    "with open(os.path.join(out_dir, \"args.txt\"), \"w\", encoding=\"utf-8\") as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "        args_txt.write(\"\\n\")\n",
    "        args_txt.write(\" \".join(sys.argv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "949504f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoding.PoissonEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d51c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
